model_providers:

  ############################ Local ############################################
  #   Uncomment this provider if you want to use local models providers         #
  #   using ollama and infinity model server                                    #
  ###############################################################################

  - provider_name: local-ollama
    api_format: openai
    base_url: http://ollama-server:11434/v1/
    api_key_env_var: ""
    llm_model_ids:
      - "qwen2:1.5b"
    embedding_model_ids: []

  - provider_name: local-infinity
    api_format: openai
    base_url: http://infinity-server:7997/
    api_key_env_var: ""
    llm_model_ids: []
    embedding_model_ids:
      - "mixedbread-ai/mxbai-embed-large-v1"

  ############################ OpenAI ###########################################
  #   Uncomment this provider if you want to use OpenAI as a models provider    #
  #   Remember to set `OPENAI_API_KEY` in container environment                 #
  ###############################################################################

#  - provider_name: openai
#    api_format: openai
#    api_key_env_var: OPENAI_API_KEY
#    llm_model_ids:
#      - "gpt-3.5-turbo"
#      - "gpt-4o"
#    embedding_model_ids:
#      - "text-embedding-3-small"
#      - "text-embedding-ada-002"


  ############################ TrueFoundry ###########################################
  #   Uncomment this provider if you want to use TrueFoundry as a models provider    #
  #   Remember to set `TFY_API_KEY` in container environment                         #
  ####################################################################################

#  - provider_name: truefoundry
#    api_format: openai
#    base_url: https://llm-gateway.truefoundry.com/api/inference/openai
#    api_key_env_var: TFY_API_KEY
#    llm_model_ids:
#      - "openai-main/gpt-4-turbo"
#      - "openai-main/gpt-3-5-turbo"
#    embedding_model_ids:
#      - "openai-main/text-embedding-ada-002"
