import typing

import requests
from servicefoundry.langchain import TruefoundryPlaygroundLLM
from servicefoundry.lib.auth.servicefoundry_session import ServiceFoundrySession

from backend.settings import settings


class TfyPlaygroundLLM(TruefoundryPlaygroundLLM):
    def _call(
        self,
        prompt: str,
        stop: typing.Optional[typing.List[str]] = None,
        **params: typing.Any,
    ) -> str:
        """Call out to the deployed model

        Args:
            prompt: The prompt to pass into the model.
            stop: Optional list of stop words to use when generating.

        Returns:
            The string generated by the model.

        Example:
            .. code-block:: python

                response = model("I have a joke for you...")
        """
        _params_already_set = self.parameters or {}
        params = {**_params_already_set, **params}
        session = ServiceFoundrySession()

        if not session:
            raise Exception(
                f"Unauthenticated: Please login using servicefoundry login --host <https://example-domain.com>"
            )

        url = f"{settings.TFY_LLM_GATEWAY_ENDPOINT}/api/inference/text"
        headers = {"Authorization": f"Bearer {session.access_token}"}

        json = {
            "prompt": prompt,
            "model": {
                "name": self.model_name,
                "parameters": params,
            },
        }
        try:
            response = requests.post(url=url, headers=headers, json=json)
            response.raise_for_status()
        except Exception as ex:
            raise Exception(f"Error inferencing the model: {ex}") from ex
        data = response.json()
        text = data.get("text")
        return text
